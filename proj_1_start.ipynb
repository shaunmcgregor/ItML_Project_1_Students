{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import gensim.downloader as api\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "#fork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 - NLP and Text Classification\n",
    "\n",
    "For this project you will need to classify some angry comments into their respective category of angry. The process that you'll need to follow is (roughly):\n",
    "<ol>\n",
    "<li> Use NLP techniques to process the training data. \n",
    "<li> Train model(s) to predict which class(es) each comment is in.\n",
    "    <ul>\n",
    "    <li> A comment can belong to any number of classes, including none. \n",
    "    </ul>\n",
    "<li> Generate predictions for each of the comments in the test data. \n",
    "<li> Write your test data predicitions to a CSV file, which will be scored. \n",
    "</ol>\n",
    "\n",
    "You can use any models and NLP libraries you'd like. Think aobut the problem, look back to see if there's anything that might help, give it a try, and see if that helps. We've regularly said we have a \"toolkit\" of things that we can use, we generally don't know which ones we'll need, but here you have a pretty simple goal - if it makes it more accurate, it helps. There's not one specific solution here, there are lots of things that you could do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "Use the training data to train your prediction model(s). Each of the classification output columns (toxic to the end) is a human label for the comment_text, assessing if it falls into that category of \"rude\". A comment may fall into any number of categories, or none at all. Membership in one output category is <b>independent</b> of membership in any of the other classes (think about this when you plan on how to make these predictions - it may also make it easier to split work amongst a team...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv.zip\")\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Creation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nltk.download('all')\n",
    "# for package in ['stopwords','punkt','wordnet']:\n",
    "#     nltk.download(package) \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class lemmaTokenizer(object):\n",
    "#     def __init__(self, stop_words):\n",
    "#         self.stop_words = stop_words\n",
    "#         self.lemmatizer = WordNetLemmatizer()\n",
    "#     def __call__(self, doc):\n",
    "#         tokens = word_tokenize(doc)\n",
    "#         filtered_tok = []\n",
    "#         for tok in tokens:\n",
    "#             if tok not in stop_words:\n",
    "#                 tok = re.sub('\\W+','', tok) #Punctuation strip\n",
    "#                 tmp = self.lemmatizer.lemmatize(tok)\n",
    "#                 if len(tmp) >= 2:\n",
    "#                     filtered_tok.append(tmp)\n",
    "#         return filtered_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tok = lemmaTokenizer(stop_words)\n",
    "#train_df[\"clean_text\"] = train_df[\"comment_text\"].apply(lambda x: tok(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = train_df[[\"id\",\"comment_text\",\"toxic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sToxic = train_df[[\"id\",\"comment_text\",\"severe_toxic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene = train_df[[\"id\",\"comment_text\",\"obscene\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat = train_df[[\"id\",\"comment_text\",\"threat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idHate = train_df[[\"id\",\"comment_text\",\"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult = train_df[[\"id\",\"comment_text\",\"insult\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelTwitter =  api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2vTwitter = dict(zip(modelTwitter.index_to_key, modelTwitter.vectors))\n",
    "\n",
    "# #for converting sentence to vectors/numbers from word vectors result by Word2Vec\n",
    "# class MeanEmbeddingVectorizer(object):\n",
    "#     def __init__(self, word2vec):\n",
    "#         self.word2vec = word2vec\n",
    "#         # if a text is empty we should return a vector of zeros\n",
    "#         # with the same dimensionality as all the other vectors\n",
    "#         self.dim = len(next(iter(word2vec.values())))\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         return np.array([\n",
    "#             np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "#                     or [np.zeros(self.dim)], axis=0)\n",
    "#             for words in X\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitterEmbedded = MeanEmbeddingVectorizer(w2vTwitter)\n",
    "twitterEmbedded = TfidfVectorizer(max_features=5000,stop_words='english')\n",
    "ctext = twitterEmbedded.fit_transform(train_df['comment_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- Clean the text of punctuation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\atrsy\\Documents\\NAIT\\Data Analytics\\DATA 3950 - Intro to Machine Learning and AI\\Project 1\\ItML_Project_1_Students\\proj_1_start.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#Word2vec\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#X_train_vectors_w2v = twitterEmbedded.transform(X_train)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#X_test_vectors_w2v = twitterEmbedded.transform(X_test)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#oversampling\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m sampler \u001b[39m=\u001b[39m SMOTETomek(n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m X_trainSamp, y_trainSamp \u001b[39m=\u001b[39m sampler\u001b[39m.\u001b[39;49mfit_resample(X_train,y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#model fitting\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atrsy/Documents/NAIT/Data%20Analytics/DATA%203950%20-%20Intro%20to%20Machine%20Learning%20and%20AI/Project%201/ItML_Project_1_Students/proj_1_start.ipynb#Y120sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m toxicModel \u001b[39m=\u001b[39m LogisticRegression(n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\imblearn\\base.py:83\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     77\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_resample(X, y)\n\u001b[0;32m     85\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[0;32m     86\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     89\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39mtransform(output[\u001b[39m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\imblearn\\combine\\_smote_tomek.py:162\u001b[0m, in \u001b[0;36mSMOTETomek._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy\n\u001b[0;32m    161\u001b[0m X_res, y_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmote_\u001b[39m.\u001b[39mfit_resample(X, y)\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtomek_\u001b[39m.\u001b[39;49mfit_resample(X_res, y_res)\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\imblearn\\base.py:83\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     77\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_resample(X, y)\n\u001b[0;32m     85\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[0;32m     86\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     89\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39mtransform(output[\u001b[39m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_tomek_links.py:139\u001b[0m, in \u001b[0;36mTomekLinks._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    137\u001b[0m nn \u001b[39m=\u001b[39m NearestNeighbors(n_neighbors\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[0;32m    138\u001b[0m nn\u001b[39m.\u001b[39mfit(X)\n\u001b[1;32m--> 139\u001b[0m nns \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[:, \u001b[39m1\u001b[39m]\n\u001b[0;32m    141\u001b[0m links \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_tomek(y, nns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_)\n\u001b[0;32m    142\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_indices_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mflatnonzero(np\u001b[39m.\u001b[39mlogical_not(links))\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m    797\u001b[0m         pairwise_distances_chunked(\n\u001b[0;32m    798\u001b[0m             X,\n\u001b[0;32m    799\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[0;32m    800\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[0;32m    801\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[0;32m    802\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    803\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[0;32m    804\u001b[0m         )\n\u001b[0;32m    805\u001b[0m     )\n\u001b[0;32m    807\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39mmetric, n_jobs\u001b[39m=\u001b[39mn_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1568\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1566\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n\u001b[0;32m   1567\u001b[0m ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1568\u001b[0m Parallel(backend\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreading\u001b[39;49m\u001b[39m\"\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49mn_jobs)(\n\u001b[0;32m   1569\u001b[0m     fd(func, ret, s, X, Y[s], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m gen_even_slices(_num_samples(Y), effective_n_jobs(n_jobs))\n\u001b[0;32m   1571\u001b[0m )\n\u001b[0;32m   1573\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1574\u001b[0m     \u001b[39m# zeroing diagonal for euclidean norm.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m     \u001b[39m# TODO: do it also for other norms.\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m     np\u001b[39m.\u001b[39mfill_diagonal(ret, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\multiprocessing\\pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    572\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 574\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\atrsy\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "toxic = train_df[[\"id\",\"comment_text\",\"toxic\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(ctext,toxic[\"toxic\"])\n",
    "\n",
    "#Word2vec\n",
    "#X_train_vectors_w2v = twitterEmbedded.transform(X_train)\n",
    "#X_test_vectors_w2v = twitterEmbedded.transform(X_test)\n",
    "\n",
    "#oversampling\n",
    "#sampler = SMOTETomek(n_jobs=-1)\n",
    "#X_trainSamp, y_trainSamp = sampler.fit_resample(X_train,y_train)\n",
    "\n",
    "#model fitting\n",
    "toxicModel = LogisticRegression(n_jobs=-1)\n",
    "toxicModel.fit(X_train, y_train)\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = toxicModel.predict(X_test)\n",
    "y_prob = toxicModel.predict_proba(X_test)[:,1]\n",
    " \n",
    "#calculate scores\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)  \n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Severely Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(sToxic[\"clean_text\"],sToxic[\"severe_toxic\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# severeMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = severeMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = severeMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# severeModel = RandomForestClassifier()\n",
    "# severeModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = severeModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = severeModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(obscene[\"clean_text\"],obscene[\"obscene\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# obsceneMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = obsceneMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = obsceneMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# obsceneModel = RandomForestClassifier()\n",
    "# obsceneModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = obsceneModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = obsceneModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(insult[\"clean_text\"],insult[\"insult\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# insultMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = insultMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = insultMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# insultModel = RandomForestClassifier()\n",
    "# insultModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = insultModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = insultModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(idHate[\"clean_text\"],idHate[\"identity_hate\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# idHateMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = idHateMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = idHateMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# idHatePredictionModel = RandomForestClassifier()\n",
    "# idHatePredictionModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = idHatePredictionModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = idHatePredictionModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(threat[\"clean_text\"],threat[\"threat\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# threatVectorizeModel = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = threatVectorizeModel.transform(X_train)\n",
    "# X_test_vectors_w2v = threatVectorizeModel.transform(X_test)\n",
    "\n",
    "# threatPredictionModel = RandomForestClassifier()\n",
    "# threatPredictionModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = threatPredictionModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = threatPredictionModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"clean_text\"] = test_df[\"comment_text\"].apply(lambda x: tok(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toxic final prediction\n",
    "# test_vectors_toxic = toxicMeanEmbedVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yToxic = toxicModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Severely toxic final prediction\n",
    "# test_vectors_severe = severeMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# ySevere = severeModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Obscene final prediction\n",
    "# test_vectors_obscene = obsceneMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yObscene = obsceneModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Insult final prediction\n",
    "# test_vectors_insult = insultMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yInsult = insultModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Identity Hate final prediction\n",
    "# test_vectors_idhate = idHateMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yIDHate = idHatePredictionModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Threat final prediction\n",
    "# test_vectors_threat = threatVectorizeModel.transform(test_df[\"clean_text\"])\n",
    "# yThreat = threatPredictionModel.predict(test_vectors_toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now kith\n",
    "# columns = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "# thisIsGoingOut = pd.DataFrame(list(zip(test_df[\"id\"], yToxic, ySevere,yObscene, yThreat, yInsult, yIDHate)),\n",
    "#                               columns=columns)\n",
    "# thisIsGoingOut.to_csv('out.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Details, Submission Info, and Example Submission\n",
    "\n",
    "For this project, please output your predictions in a CSV file. The structure of the CSV file should match the structure of the example below. \n",
    "\n",
    "The output should contain one row for each row of test data, complete with the columns for ID and each classification.\n",
    "\n",
    "Into Moodle please submit:\n",
    "<ul>\n",
    "<li> Your notebook file(s). I'm not going to run them, just look. \n",
    "<li> Your sample submission CSV. This will be evaluated for accuracy against the real labels; only a subset of the predictions will be scored. \n",
    "</ul>\n",
    "\n",
    "It is REALLY, REALLY, REALLY important the the structure of your output matches the specifications. The accuracies will be calculated by a script, and it is expecting a specific format. \n",
    "\n",
    "### Sample Evaluator\n",
    "\n",
    "The file prediction_evaluator.ipynb contains an example scoring function, scoreChecker. This function takes a sumbission and an answer key, loops through, and evaluates the accuracy. You can use this to verify the format of your submission. I'm going to use the same function to evaluate the accuracy of your submission, against the answer key (unless I made some mistake in this counting function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct dummy data for a sample output. \n",
    "#You won't do this part first, you have real data - I'm faking it. \n",
    "#Your data should have the same structure, so the CSV output is the same\n",
    "# dummy_ids = [\"dfasdf234\", \"asdfgw43r52\", \"asdgtawe4\", \"wqtr215432\"]\n",
    "# dummy_toxic = [0,0,0,0]\n",
    "# dummy_severe = [0,0,0,0]\n",
    "# dummy_obscene = [0,1,1,0]\n",
    "# dummy_threat = [0,1,0,1]\n",
    "# dummy_insult = [0,0,1,0]\n",
    "# dummy_ident = [0,1,1,0]\n",
    "# columns = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "# sample_out = pd.DataFrame( list(zip(dummy_ids, dummy_toxic, dummy_severe, dummy_obscene, dummy_threat, dummy_insult, dummy_ident)),\n",
    "#                     columns=columns)\n",
    "# sample_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write DF to CSV. Please keep the \"out.csv\" filename. Moodle will auto-preface it with an identifier when I download it. \n",
    "#This command should work with your dataframe of predictions. \n",
    "# sample_out.to_csv('out.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "The grading for this is split between accuracy and well written code:\n",
    "<ul>\n",
    "<li> 75% - Accuracy. The most accurate will get 100% on this, the others will be scaled down from there. \n",
    "<li> 25% - Code quality. Can the code be followed and made sense of - i.e. comments, sections, titles. \n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8db638d3b940bd10adfd3e31b9d30944957c89679bddca81ff9d9cb86f7e1de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
