{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import gensim.downloader as api\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "#fork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 - NLP and Text Classification\n",
    "\n",
    "For this project you will need to classify some angry comments into their respective category of angry. The process that you'll need to follow is (roughly):\n",
    "<ol>\n",
    "<li> Use NLP techniques to process the training data. \n",
    "<li> Train model(s) to predict which class(es) each comment is in.\n",
    "    <ul>\n",
    "    <li> A comment can belong to any number of classes, including none. \n",
    "    </ul>\n",
    "<li> Generate predictions for each of the comments in the test data. \n",
    "<li> Write your test data predicitions to a CSV file, which will be scored. \n",
    "</ol>\n",
    "\n",
    "You can use any models and NLP libraries you'd like. Think aobut the problem, look back to see if there's anything that might help, give it a try, and see if that helps. We've regularly said we have a \"toolkit\" of things that we can use, we generally don't know which ones we'll need, but here you have a pretty simple goal - if it makes it more accurate, it helps. There's not one specific solution here, there are lots of things that you could do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "Use the training data to train your prediction model(s). Each of the classification output columns (toxic to the end) is a human label for the comment_text, assessing if it falls into that category of \"rude\". A comment may fall into any number of categories, or none at all. Membership in one output category is <b>independent</b> of membership in any of the other classes (think about this when you plan on how to make these predictions - it may also make it easier to split work amongst a team...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv.zip\")\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Creation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nltk.download('all')\n",
    "# for package in ['stopwords','punkt','wordnet']:\n",
    "#     nltk.download(package) \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lemmaTokenizer(object):\n",
    "    def __init__(self, stop_words):\n",
    "        self.stop_words = stop_words\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        filtered_tok = []\n",
    "        for tok in tokens:\n",
    "            if tok not in stop_words:\n",
    "                tok = re.sub('\\W+','', tok) #Punctuation strip\n",
    "                tmp = self.lemmatizer.lemmatize(tok)\n",
    "                if len(tmp) >= 2:\n",
    "                    filtered_tok.append(tmp)\n",
    "        return filtered_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = lemmaTokenizer(stop_words)\n",
    "train_df[\"clean_text\"] = train_df[\"comment_text\"].apply(lambda x: tok(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "159566      0  \n",
       "159567      0  \n",
       "159568      0  \n",
       "159569      0  \n",
       "159570      0  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic = train_df[[\"id\",\"comment_text\",\"toxic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sToxic = train_df[[\"id\",\"comment_text\",\"severe_toxic\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene = train_df[[\"id\",\"comment_text\",\"obscene\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat = train_df[[\"id\",\"comment_text\",\"threat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idHate = train_df[[\"id\",\"comment_text\",\"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult = train_df[[\"id\",\"comment_text\",\"insult\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "modelTwitter =  api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vTwitter = dict(zip(modelTwitter.index_to_key, modelTwitter.vectors))\n",
    "\n",
    "#for converting sentence to vectors/numbers from word vectors result by Word2Vec\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterEmbedded = MeanEmbeddingVectorizer(w2vTwitter)\n",
    "# twitterTfid = TfidVectorizer(w2vTwitter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems\n",
    "- All the samples are unbalanced, we need to fix that\n",
    "- we've got real bad recall and f1 on most of the classifiers we need to sort that out.\n",
    "- maybe we could try using one of the pre-trained w2v models and see if that helps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8871503140156665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     36037\n",
      "           1       0.82      0.32      0.46      3856\n",
      "\n",
      "    accuracy                           0.93     39893\n",
      "   macro avg       0.88      0.66      0.71     39893\n",
      "weighted avg       0.92      0.93      0.91     39893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " from sklearn import naive_bayes\n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "toxic = train_df[[\"id\",\"clean_text\",\"toxic\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(toxic[\"clean_text\"],toxic[\"toxic\"])\n",
    "\n",
    "#Word2vec\n",
    "X_train_vectors_w2v = twitterEmbedded.transform(X_train)\n",
    "X_test_vectors_w2v = twitterEmbedded.transform(X_test)\n",
    "\n",
    "#oversampling\n",
    "sampler = TomekLinks(sampling_strategy=\"not majority\", n_jobs=-1)\n",
    "X_trainSamp, y_trainSamp = sampler.fit_resample(X_train_vectors_w2v,y_train)\n",
    "\n",
    "#model fitting\n",
    "toxicModel = (n_jobs=-1)\n",
    "toxicModel.fit(X_trainSamp, y_trainSamp)\n",
    "\n",
    "#Predict y value for test dataset\n",
    "y_predict = toxicModel.predict(X_test_vectors_w2v)\n",
    "y_prob = toxicModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "#calculate scores\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)  \n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Severely Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(sToxic[\"clean_text\"],sToxic[\"severe_toxic\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# severeMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = severeMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = severeMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# severeModel = RandomForestClassifier()\n",
    "# severeModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = severeModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = severeModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(obscene[\"clean_text\"],obscene[\"obscene\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# obsceneMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = obsceneMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = obsceneMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# obsceneModel = RandomForestClassifier()\n",
    "# obsceneModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = obsceneModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = obsceneModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(insult[\"clean_text\"],insult[\"insult\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# insultMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = insultMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = insultMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# insultModel = RandomForestClassifier()\n",
    "# insultModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = insultModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = insultModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(idHate[\"clean_text\"],idHate[\"identity_hate\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# idHateMeanEmbeddingVectorizer = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = idHateMeanEmbeddingVectorizer.transform(X_train)\n",
    "# X_test_vectors_w2v = idHateMeanEmbeddingVectorizer.transform(X_test)\n",
    "\n",
    "# idHatePredictionModel = RandomForestClassifier()\n",
    "# idHatePredictionModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = idHatePredictionModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = idHatePredictionModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
    " \n",
    "# Split data - using the new dataframe parts that we cleaned up. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(threat[\"clean_text\"],threat[\"threat\"])\n",
    "\n",
    "# #Word2vec\n",
    "# # Fit and transform\n",
    "# threatVectorizeModel = MeanEmbeddingVectorizer(w2vToxic)\n",
    "\n",
    "# X_train_vectors_w2v = threatVectorizeModel.transform(X_train)\n",
    "# X_test_vectors_w2v = threatVectorizeModel.transform(X_test)\n",
    "\n",
    "# threatPredictionModel = RandomForestClassifier()\n",
    "# threatPredictionModel.fit(X_train_vectors_w2v, y_train)  #model\n",
    "\n",
    "# #Predict y value for test dataset\n",
    "# y_predict = threatPredictionModel.predict(X_test_vectors_w2v)\n",
    "# y_prob = threatPredictionModel.predict_proba(X_test_vectors_w2v)[:,1]\n",
    " \n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print('AUC:', roc_auc)  \n",
    "\n",
    "# print(classification_report(y_test, y_predict))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_predict), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"clean_text\"] = test_df[\"comment_text\"].apply(lambda x: tok(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toxic final prediction\n",
    "# test_vectors_toxic = toxicMeanEmbedVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yToxic = toxicModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Severely toxic final prediction\n",
    "# test_vectors_severe = severeMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# ySevere = severeModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Obscene final prediction\n",
    "# test_vectors_obscene = obsceneMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yObscene = obsceneModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Insult final prediction\n",
    "# test_vectors_insult = insultMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yInsult = insultModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Identity Hate final prediction\n",
    "# test_vectors_idhate = idHateMeanEmbeddingVectorizer.transform(test_df[\"clean_text\"])\n",
    "# yIDHate = idHatePredictionModel.predict(test_vectors_toxic)\n",
    "\n",
    "# #Threat final prediction\n",
    "# test_vectors_threat = threatVectorizeModel.transform(test_df[\"clean_text\"])\n",
    "# yThreat = threatPredictionModel.predict(test_vectors_toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now kith\n",
    "# columns = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "# thisIsGoingOut = pd.DataFrame(list(zip(test_df[\"id\"], yToxic, ySevere,yObscene, yThreat, yInsult, yIDHate)),\n",
    "#                               columns=columns)\n",
    "# thisIsGoingOut.to_csv('out.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Details, Submission Info, and Example Submission\n",
    "\n",
    "For this project, please output your predictions in a CSV file. The structure of the CSV file should match the structure of the example below. \n",
    "\n",
    "The output should contain one row for each row of test data, complete with the columns for ID and each classification.\n",
    "\n",
    "Into Moodle please submit:\n",
    "<ul>\n",
    "<li> Your notebook file(s). I'm not going to run them, just look. \n",
    "<li> Your sample submission CSV. This will be evaluated for accuracy against the real labels; only a subset of the predictions will be scored. \n",
    "</ul>\n",
    "\n",
    "It is REALLY, REALLY, REALLY important the the structure of your output matches the specifications. The accuracies will be calculated by a script, and it is expecting a specific format. \n",
    "\n",
    "### Sample Evaluator\n",
    "\n",
    "The file prediction_evaluator.ipynb contains an example scoring function, scoreChecker. This function takes a sumbission and an answer key, loops through, and evaluates the accuracy. You can use this to verify the format of your submission. I'm going to use the same function to evaluate the accuracy of your submission, against the answer key (unless I made some mistake in this counting function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct dummy data for a sample output. \n",
    "#You won't do this part first, you have real data - I'm faking it. \n",
    "#Your data should have the same structure, so the CSV output is the same\n",
    "# dummy_ids = [\"dfasdf234\", \"asdfgw43r52\", \"asdgtawe4\", \"wqtr215432\"]\n",
    "# dummy_toxic = [0,0,0,0]\n",
    "# dummy_severe = [0,0,0,0]\n",
    "# dummy_obscene = [0,1,1,0]\n",
    "# dummy_threat = [0,1,0,1]\n",
    "# dummy_insult = [0,0,1,0]\n",
    "# dummy_ident = [0,1,1,0]\n",
    "# columns = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "# sample_out = pd.DataFrame( list(zip(dummy_ids, dummy_toxic, dummy_severe, dummy_obscene, dummy_threat, dummy_insult, dummy_ident)),\n",
    "#                     columns=columns)\n",
    "# sample_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write DF to CSV. Please keep the \"out.csv\" filename. Moodle will auto-preface it with an identifier when I download it. \n",
    "#This command should work with your dataframe of predictions. \n",
    "# sample_out.to_csv('out.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "The grading for this is split between accuracy and well written code:\n",
    "<ul>\n",
    "<li> 75% - Accuracy. The most accurate will get 100% on this, the others will be scaled down from there. \n",
    "<li> 25% - Code quality. Can the code be followed and made sense of - i.e. comments, sections, titles. \n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8db638d3b940bd10adfd3e31b9d30944957c89679bddca81ff9d9cb86f7e1de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
